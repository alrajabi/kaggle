{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elephant.jpg\n",
      "first_try.h5\n",
      "test_train.ipynb\n",
      "train_example.bson\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "## ------------------ from kaggle:\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./\"]).decode(\"utf8\"))\n",
    "import io\n",
    "import bson                       # this is installed with the pymongo package\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.data import imread   # or, whatever image library you prefer\n",
    "import multiprocessing as mp  # will come in handy due to the size of the data\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False, input_shape=(180,180,3) )\n",
    "\n",
    "#img_path = 'elephant.jpg'\n",
    "#img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "%matplotlib inline\n",
    "data = bson.decode_file_iter(open('./train_example.bson', 'rb'))\n",
    "\n",
    "prod_to_category = dict()\n",
    "ndim = 180*180*3\n",
    "counter = 0\n",
    "feat_arr = []\n",
    "cat_arr =[]\n",
    "for c, d in enumerate(data):\n",
    "    product_id = d['_id']\n",
    "    category_id = d['category_id'] # This won't be in Test data\n",
    "    prod_to_category[product_id] = category_id\n",
    "    #counter += 1\n",
    "    for e, pic in enumerate(d['imgs']):\n",
    "        picture = imread(io.BytesIO(pic['picture']))\n",
    "        cat_arr.append(product_id)\n",
    "        #print(e, \" \", pic)\n",
    "        #plt.imshow(picture)\n",
    "        #plt.show()\n",
    "        #picture = np.array(picture).reshape(ndim,1)\n",
    "        #print(picture.shape)\n",
    "        counter += 1\n",
    "        # do something with the picture, etc\n",
    "        x = image.img_to_array(picture)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        # decode the results into a list of tuples (class, description, probability)\n",
    "        # (one such list for each sample in the batch)\n",
    "        features = model.predict(x)\n",
    "        feat_arr.append(features)\n",
    "        #print('Predicted:', decode_predictions(features, top=3)[0])\n",
    "        #print('Features:', features.shape)\n",
    "#print(counter)\n",
    "#print('Predicted:', decode_predictions(features, top=3)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_arr = np.asarray(cat_arr)\n",
    "cat_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.backend import one_hot\n",
    "prod_arr = cat_arr\n",
    "prod_arr_1 = one_hot(prod_arr, 82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(110), Dimension(82)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_arr_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_dict = dict(zip(list(set(cat_arr)), range(82)))\n",
    "y_int = np.array([y_dict[category_id] for category_id in cat_arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "one_hot_labels = to_categorical(y_int, num_classes=82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_arr = np.asarray(feat_arr)\n",
    "feat_arr.shape\n",
    "feat_arr_temp = feat_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 5, 5, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_arr_temp = feat_arr_temp.reshape((110,5,5,512))\n",
    "feat_arr_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Flatten(input_shape=(5,5,512)))\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(82, activation='softmax'))\n",
    "model2.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "110/110 [==============================] - 0s - loss: 0.3587 - acc: 0.9772     \n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 0s - loss: 0.3569 - acc: 0.9772     \n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 0s - loss: 0.3500 - acc: 0.9776     \n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 0s - loss: 0.3593 - acc: 0.9774     \n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 0s - loss: 0.3530 - acc: 0.9774     \n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 0s - loss: 0.3536 - acc: 0.9774     \n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 0s - loss: 0.3561 - acc: 0.9774     \n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 0s - loss: 0.3578 - acc: 0.9769     \n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 0s - loss: 0.3554 - acc: 0.9776     \n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 0s - loss: 0.3586 - acc: 0.9774     \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'decode_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-dcad0e0249b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmyfirstpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_arr_temp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mone_hot_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdecode_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyfirstpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'decode_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "myfirstpred = model2.fit(feat_arr_temp,one_hot_labels)\n",
    "decode_predictions(myfirstpred)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 5, 5, 512)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(category_id)\n",
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 512)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_arr[0].shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-004fff7346f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m generator = datagen.flow_from_directory(\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;34m'./'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m180\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datagen' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 16\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        './',\n",
    "        target_size=(180, 180),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # this means our generator will only yield batches of data, no labels\n",
    "        shuffle=False)  # our data will be in order, so all first 1000 images will be cats, then 1000 dogs\n",
    "# the predict_generator method returns the output of a model, given\n",
    "# a generator that yields batches of numpy data\n",
    "bottleneck_features_train = model.predict_generator(generator, 2000)\n",
    "# save the output as a Numpy array\n",
    "np.save(open('bottleneck_features_train.npy', 'w'), bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Predicted:', [(u'n03584254', u'iPod', 0.28128624), (u'n02992529', u'cellular_telephone', 0.22903134), (u'n02978881', u'cassette', 0.050575905)])\n"
     ]
    }
   ],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "prod_to_category = pd.DataFrame.from_dict(prod_to_category, orient='index')\n",
    "prod_to_category.index.name = '_id'\n",
    "prod_to_category.rename(columns={0: 'category_id'}, inplace=True)\n",
    "print(picture.shape)\n",
    "prod_to_category\n",
    "\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = 'elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Predicted:', [(u'n03584254', u'iPod', 0.28128734), (u'n02992529', u'cellular_telephone', 0.22903137), (u'n02978881', u'cassette', 0.05057567), (u'n03871628', u'packet', 0.040722415), (u'n04074963', u'remote_control', 0.032242771), (u'n03485407', u'hand-held_computer', 0.024945108), (u'n04548362', u'wallet', 0.023825444), (u'n04404412', u'television', 0.022865141), (u'n04476259', u'tray', 0.017864024), (u'n03666591', u'lighter', 0.013523093)])\n"
     ]
    }
   ],
   "source": [
    "print('Predicted:', decode_predictions(preds, top=10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
